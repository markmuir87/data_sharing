{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is a very early draft. Source code on https://github.com/monkeypants/data_sharing/, pull requests welcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Why is so much public data hidden?\n",
    "\n",
    "Government policy mandates that publicaly owned data should be shared by default (and hidden by exception) [TODO: insert relevant link]. Sometimes public data is hidden to protect the people or objects that the data is about. Sometimes this data is hidden because of specific protections in law. Often it is hidden because public servants make ballanced judgement decisions about sharing (or hiding) publically owned data.\n",
    "\n",
    "The purpose of this repository is to explore the last of the above categories; judgement decisions made by public servants to share or hide public data. I'm looking for answers to these questions:\n",
    "\n",
    " * Are we striking the right ballance, or are we hiding/sharing more than we should be?\n",
    " * Why data is hidden when it should be shared?\n",
    " * Why is data shared when it should be hidden?\n",
    " * What factors influence data sharing/hiding decisions?\n",
    " * How can we optimise the decision making process? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the evidence\n",
    "\n",
    "TODO: Case studies:\n",
    "* evidence of practical challenges to data sharing\n",
    "* evidence that data sharing challenges can be overcome\n",
    "\n",
    "TODO: Surveys, questionaires, interviews, existing data, new research...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models of data sharing/hiding decisions\n",
    "\n",
    "There are two ways to consider data sharing/hiding decisions. One is to consider them as binary decisions (to either share or hide), in which case we can use ROC Curve analysis to examine decision making performance. This analysis applies to \"forced choice decisions\" when a public servant must decide one way or the other (\"no decision\" is not an option). This kind of analysis may prove useful for designing policy levers and settings to achieve consistently good decisions under controlled circumstances. In other words, it is a way to study formal sharing/hidnig approval process that are executed at a middle mamagement tier.\n",
    "\n",
    "An other way to consider sharing/hiding decisions is using a behavioral paradigm. In other words, treat a \"decision to share data\" as a contextural choice event, like the decision to answer a ringing phone, scratch an itch, check your email or multiask some combination thereoff. By analysing data sharing decisions as \"situated actions\", we gain a \n",
    "behavioral perspective which may be useful for determining how context can be maniulated to achieve optimum decisions. This is a way to study informal sharing/hiding decisions, and the influence of organisational culture at a personal level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# \"Share or Hide\" is a binary classifier\n",
    "\n",
    "Binary classification systems have been studdied by electrical engineers since the development of radar during WWII, and are represented as a body of knowledge known as Signal Detection Theory (SDT). Techniques from SDT are also applied in psychometric analysis to study sensation and perception, as well as analysis of binary (forced-choice) decisions in psychology.\n",
    "\n",
    "In Signal Detection Theory, performance of binary classifiers are studdied by experiments that measure:\n",
    "\n",
    "* Hits: corectly detecting a stimulus, signal or enemy warship\n",
    "* Misses: failing to detect a signal when present\n",
    "* Correct rejections: indicating that no signal is present when there is in fact no signal\n",
    "* False alarms: indicating a signal is present when there is none\n",
    "\n",
    "Put another way, the result of binary classification experiment is measured as a classification table:\n",
    "\n",
    "| Decision | Correct           | Incorrect   |\n",
    "|----------|-------------------|-------------|\n",
    "| Yes      | Hit               | False Alarm |\n",
    "| No       | Correct rejection | Miss        |\n",
    "\n",
    "Assuming a binary model for data sharing/hiding decisions, we can form an equivalent classification table:\n",
    "\n",
    "| Decision   | Correct               | Wrong                   |\n",
    "|------------|-----------------------|-------------------------|\n",
    "| Share data | Correctly shared data | Incorrectly shared data |\n",
    "| Hide data  | Correctly hidden data | Incorrectly hidden data |\n",
    "\n",
    "\n",
    "SDT analysis allows us to study bias (sensitivity and specificity) and performance (area under the receiver operating characteristic curve) of binary classifiers. \n",
    "\n",
    "\n",
    "## Sensitivity\n",
    "\n",
    "Arguments in favour of data sharing focus on the social, econnomic and environmental value derived from \"correctly shared data\". The cost of \"incorrectly hidden data\" is the failure to realise this value.\n",
    "\n",
    "* if we shared no data at all, we would recieve none of the sharing benefit.\n",
    "* If we shared all data, we would recieve all the sharing benefit.\n",
    "\n",
    "Signal Detection Theory defines the \"True Positive Rate\" (TPR or classifier \"sensitivity\") as the ratio of Hits to False Alarms. In our case, the TPR is ratio of correctly shared data to incorrectly shared data.\n",
    "\n",
    "$$\\text{sensitivity} = \\frac{\\text{correctly shared data}}{\\text{incorrectly shared data}}$$\n",
    "\n",
    "We should aim to understand the TPR of data sharing decisions, how we can maximise the sensitivity to achieve the most value. If everything else was held constant, and we managed to increase the sensitivity of the classifier, we would increase it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specificity\n",
    "\n",
    "Arguments in favour of data hiding focus on the social, econnomic and environmental risk derived from \"incorectly shared data\". The benefits of \"correctly hidden data\" are the counterpoint of this.\n",
    "\n",
    "* if we shared all the data we would be exposed to the full risk\n",
    "* if we shared no data at all we would be exposed to none of the risk\n",
    "\n",
    "Signal Detection Theory defines the \"False Positive Rate\" (FPR or classifier \"specificity\") as the ratio of correct rejections to misses. In our case, the FPR is the ratio of correctly hidden data to incorrectly hidden data. \n",
    "\n",
    "$$\\text{specificity} = \\frac{\\text{correctly hidden data}}{\\text{incorrectly hidden data}}$$\n",
    "\n",
    "We should aim to understand the FPR of data hiding decisions, how we can maximise the specificity to mitigate risk with the best efficiency. All else being equal, of we managed to increase the specificty of a binary classifier, we would increase it's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "\n",
    "Many types of binary classifiers can be *tuned* to either avoid misses (increase sensitivity) or avoid false alarms (increase specificity). This tuning does not make the classifier more or less accurate, sensitivity is sacrificed to increase specificity (and vica versa, no free lunch). The word \"bias\" is used to describe changes which trade-off sensitivity for specificity (and vica-verca).\n",
    "\n",
    "Changing a classifier to increases it's sensitivity and specificity both together do increase it's performance, independant of bias. These kinds of changes generally involve giving the classifier more information, or using the information it has more efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias\n",
    "\n",
    "Wikipedia defined bias as \"is an inclination or outlook to present or hold a partial perspective\" (https://en.wikipedia.org/wiki/Bias). In data sharing/hiding decisions, a sharing bias means erring on the side of incorrect sharing, and a hiding bias means to err on the side of incorrect hiding. \n",
    "\n",
    "Formal processes for making data sharing decisions will have a bias that can be studied with the Signal Detection techniques, and adjusted through policy settings.\n",
    "\n",
    "* A \"data sharing bias\" will raise sensitivity and lower specificity\n",
    "* A \"data hiding bias\" will raise specificity and lower sensitivity\n",
    "\n",
    "Given an evenly distributed sample of data, a neutral bias will result in equal numbers of hide decisions and share decisions. Increasing the sensitivity will increase the number of share decisions relative to hide decisions and increasing the specificity will increase the rate of hide decisions relative to share decisions\n",
    "\n",
    "* increasing sensitivity results in a coresponding reduction in specifity\n",
    "* increasing specificity makes a coresponding reduction in sensitivity\n",
    "\n",
    "Informal factors that influence data sharing/hiding decisions (such as culture and perception) will also have systematic biases that can be studied and adjusted through eductation and messaging.\n",
    "\n",
    "The policy of \"open by default\" suggests a high sensitivity to data sharing (low rate of incorrectly hidden data). It does not imply a data sharing bias, however a data hiding bias will lower sensitivity. A data hiding bias may be the result of excessive caution, with regard to e.g. Protective Security Policy (https://protectivesecurity.gov.au)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling  bias and performance\n",
    "\n",
    "Signal Detection Theory combines FPR and TPR in a mathematical tool called Reciever Operating Characteristic Curve (ROC Curve), which is used to measure and analyse (characterise) the performance of a binary classifier (reciever) across the range of it's bias (operating settings).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "\n",
    "ROC curve analysis measures the performance of a binary classifier with an adjustable bias. One way it is useful is for comparing the performance of different binary classifiers. Another way is is useful is to show how the performance of a binary classifier changes across the spectrum of possible bias.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7989fe750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from roc_curve import demo\n",
    "demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plot, the dashed line represents a random guess binary classifier. In the middle of the plot, where the false positive rate is 0.5 (50%), the dashed line passes through the true positive rate of 0.5 as well. This mid point is neutral bias, such as a fair coin toss scenaio. The rest of the dashed line represents random guess with non-neutral bias.\n",
    "\n",
    "The blue line is a measured ROC curve of a machine learning algorithm that predicting plant taxonomy based on some sample data (see the file roc_curve.py for details). If we had the right data, we could plot a similar ROC curve \n",
    "about data sharing/decisions.\n",
    "\n",
    "We can learn a few things about our classifier by simply looking at the above plot. We can observe that above a sertain  specificity (about 0.6), the classifier never raises a false alarm (given our sample data). Even adjusting the bias so there are zero false positives, this classifier still sufficiently sensitive to identify about 15% of samples corectly. \n",
    "\n",
    "We can see that across the full range of bias, the blue line is above the dashed line so the  classifier is always superior to randomly guessing. If the blue line dipped bellow the dashed line at some point, it would actualy be worse than guessing at that bias.\n",
    "\n",
    "We can also see that the total area under the blue line is  reported on the chart (area = 0.79). This is an interesting number, because it indicates how much \"better than guessing\" the classifier is overall, for any bias setting. This number is used to compare the performance of two binary classifiers (bigger is better, 0.5 represents random guessing and 1.0 represents perfect accuracy). \n",
    "\n",
    "The ability to compare classifier performance by their \"area under the ROC curve\" works because the shape of the curve can be transformed by calibrating the axes of the plot, but calibration can not create new information (the area under the curve always remains the same). So, two classifiers with the same area under the ROC curve can be calibrated to do exactly the same job. And with the correct calibration, a classifier with a higher area under the ROC curve always has superior performance.\n",
    "\n",
    "\n",
    "## ROC curve analysis to data sharing decisions\n",
    "\n",
    "Just imagine we had some experimental apparatus that allowed us to assess the performance of various classifiers (e.g. individual public servants making share/hide decisions under a controlled circumstances) with *subjective bias*, and compare that to *objective bias* based on on consistently applied rules with full information. We could use this aparatus to both characterise classifiers (across different classes of data) and assess systematic bias.\n",
    "\n",
    "Characterising performance would allow us to:\n",
    " * compare the bias of subjective and objective classifiers\n",
    " * compare the performance of subjective and objective classifiers\n",
    " \n",
    "Note that these two things are quite different. If a subjective classifier has similar performance but different bias, then it requires calibration to adjust (*tune*) it's bias.  But if it has similar bias but different performance, then it we need to treat the decision differently (change the *context*); such as providing more information, deconflicted guidance, or adjustments to policy or legislation.  \n",
    "\n",
    "Before profitably applying ROC curve analysis to data sharing decisions, we need theories that can be tested with experiments, that can be used to identify actions which will result in better outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## theory 1: data sharing suffers from a tragedy of the commons\n",
    "\n",
    "The asymetric personal ecconomic consequence results in a pattern called \"the tradgedy of the commons\", which results in sub-optimal value. Data sharing decision makers are naturally expected to have an inherent bias which will result in missed oportunities to share data that should have been shared, while scruprulously avoiding data sharing that should not be shared.\n",
    "\n",
    "```\n",
    "The negative consequences of incorrect-sharing are born personally (ecconomic internality)\n",
    "by the decision maker, however the consequences of correct sharing are an ecconomic externality.\n",
    "Across all types of data, there will be a systematic data-hiding bias.\n",
    "```\n",
    "\n",
    "A bias towards \"hiding data at any excuse\" will result in a loss of utility for society, the economy and the environment. These are ecconomic externalities to the decision maker, who is not personally affected in a significant way.\n",
    "\n",
    "An bias towards \"sharing data regardless of risks\" will directly expose the Government, Agency and Public Servant themselves to risk. There would be comparatably less risk for society, the ecconomy and the environment. This is an ecconomic internality to the decision maker.\n",
    "\n",
    "If this theory is true, bias will be in evidence (\"Incorrectly hidden\" rate will be higher than \"Incorrectly shared\" rate). This theory could be evaluated empirically by disproving the following null Hypothesese:\n",
    "\n",
    " * mitigating personal consequence of incorrect sharing will NOT improve performance\n",
    " * mitigating personal consequence of incorrect sharing will NOT reduce hiding bias\n",
    " * internalising value of correct sharing will NOT improve performance\n",
    " * internalising value of correct sharing will NOT reduce hiding bias\n",
    "\n",
    "If this theory is strongly supported by evidence, it would suggest a strategic requirement to achieve some or all of the following:\n",
    " * Improve specificity of data-hiding factors. For example, clarify and deconflict guidance for decision makers.\n",
    " * Create mechanisms that mitigate personal consequence of incorrect sharing. For example, an appropriately governed proxy that takes responsability for incorrectly shared data.\n",
    " * Create mechanisms that internalise the benefits of correct data sharing. For example, recognise and reward correct data sharing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## theory 2: data sharing decisions are influenced by the psychology of risk aversion \n",
    "\n",
    "The benefits of data sharing are difficult to quantify, because exactly when and how data will prove useful can be very difficult to predict. This creates a perception that the cost of hiding-bias has high uncertainty.\n",
    "\n",
    "The cost of bias towards sharing data seems easier to predict. Damaged reputations, a damaged carrear and possibly even gaol. This creates a perception that the cost of sharing-bias has low uncertainty.\n",
    "\n",
    "These are the conditions which result in the psychological phenomina known as risk aversion.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Risk_aversion_%28psychology%29\n",
    "\n",
    "If data sharing decisions are being influenced by risk aversion, this will result in data-hiding bias.\n",
    "\n",
    "This theory could be evaluated empirically by disproving the following null Hypothesese:\n",
    " * increasing uncertainty about the consequences of incorrect sharing will NOT reduce hiding bias\n",
    " * increasing uncertainty about the consequences of incorrect sharing will NOT increase performance\n",
    " * decreasing uncertainty about the concequence of correct sharing will NOT reduce hiding bias\n",
    " * decreasing uncertainty about the consequence of correct sharing will NOT increase performance\n",
    "\n",
    "\n",
    "If this theory is strongly supported by evidence, it would suggest a strategic requirement to achieve some or all of the following:\n",
    " * Create predictable benefits of correct sharing (e.g. link sharing performance to funding).\n",
    " * Manufacture uncertainty around the negative consequence of incorrect sharing (e.g. manufacture doubt.\n",
    " *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# untangle...\n",
    "\n",
    "The rest of these words have been removed from the above, but not quite deleted as they are reminders for ideas that I want to put back in.\n",
    "\n",
    "\n",
    "Subjective / Objective risk mismatch\n",
    "\n",
    "\n",
    "Some data will be safe to share and high valuable, other data will be dangerous to share and low value\n",
    "\n",
    "This means the optimal performing classifier will display a appropriate bias to account for the different misclassification costs. This \"optimum bias\" will be different for different data.\n",
    "\n",
    "It's easy to miss an important point here: The bias that is measured/characterised by ROC Cruve analysis is exactly the same thing as the relative assessments of costs and risks made by the data sharing/hiding decision maker, in a binary forced-choice decision situation. By measuring one, we measure the other.\n",
    "\n",
    "If we are able to conduct experiments that allow us to perform ROC Curve analysis on data sharing/hiding decisions in a specific context, then we will be directly measuring the subjective risk and value assessments of the decision maker.\n",
    "\n",
    "This would create two opportunities:\n",
    "* compare subjective and objective risk/value assessment, to evaluate opportunities to improve performance through providing better information and adressing dysfunctional cultural norms\n",
    "* understand the impact on decision performance of \"adjusting sensitivity\", e.g. by recalibrating risk posture\n",
    "\n",
    "More Reading:\n",
    "* example of comparative analysis in OH&S Domain: http://www.tandfonline.com/doi/pdf/10.1080/10803548.2010.11076826\n",
    "* https://en.wikipedia.org/wiki/Risk_aversion_%28psychology%29\n",
    "\n",
    "\n",
    "## The deeper question: To share or not to share\n",
    "\n",
    "Once we have the apparatus to experiment with forced-choice data sharing decisions, we will have the ability to model and measure the domain, identify and correct cultural bias, and adopt the most appropriate risk posture for optimal outcomes.\n",
    "\n",
    "The next step is to study how culture and context can be \"nudged\" to manipulate sharing/hiding decisions, such that subjective and objective risks are aligned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
