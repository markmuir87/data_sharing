{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Why is so much public data hidden?\n",
    "\n",
    "Government policy mandates: By default, publicaly owned data should be shared (and hidden by exception). Sometimes public data is hidden to protect the people or objects that the data is about. Sometimes this data is hidden because of specific protections in law. Often it is hidden because public servants make ballanced judgement decisions about sharing (or hiding) publically owned data.\n",
    "\n",
    "The purpose of this repository is to explore the last of the above categories; judgement decisions made by public servants to share or hide public data.\n",
    "\n",
    " * Are we striking the right ballance, or are we hiding/sharing more than we should be?\n",
    " * Why data is hidden when it should be shared?\n",
    " * Why is data shared when it should be hidden?\n",
    " * What factors influence data sharing/hiding decisions?\n",
    " * How can we optimise the decision making process? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case studies:\n",
    "\n",
    "* evidence of practical challenges to data sharing\n",
    "* evidence that data sharing challenges can be overcome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the ballance struck?\n",
    "\n",
    "There are two ways to consider data sharing/hiding decisions. One is to consider them as binary decisions (to either share or hide), in which case we can use ROC Curve analysis to examine decision making performance. This analysis applies to \"forced choice decisions\" when a public servant must decide one way or the other (\"no decision\" is not an option). This kind of analysis may prove useful for designing policy levers and settings to achieve consistently good decisions.\n",
    "\n",
    "An other way to consider sharing/hiding decisions is using a behavioral paradigm. In other words, treat a \"decision to share data\" as a contextural choice event. A \"decision to hide data\" would also be a contextural choice event, but so might \"decidision to create data\" and \"decisions to avoid making a decision\". This style of analysis may be useful as the basis for experimentatly determining how the decision making context can be maniulated to achieve optimum choice decision outcomes.\n",
    "\n",
    "\n",
    "## \"Share or Hide\" is a binary classifier\n",
    "\n",
    "Binary classification systems have been studdied by electrical engineers since the development of radar during WWII, and are represented a body of knowledge known as Signal Detection Theory (SDT). Techniques from SDT are also applied in psychometric analysis to study sensation and perception, as well as analysis of binary (forced-choice) decisions in psychology.\n",
    "\n",
    "In Signal Detection Theory, performance of binary classifiers are studdied by experiments that measure:\n",
    "* Hits: corectly detecting a stimulus, signal or enemy warship\n",
    "* Misses: failing to detect a signal when present\n",
    "* Correct rejections: indicating that no signal is present when there is in fact no signal\n",
    "* False alarms: indicating a signal is present when there is none\n",
    "\n",
    "Put another way, the following classification performances are measured:\n",
    "\n",
    "| Decision      | Correct           | Incorrect   |\n",
    "|---------------|-------------------|-------------|\n",
    "| Present/True  | Hit               | False Alarm |\n",
    "| Absent/False  | Correct rejection | Miss        |\n",
    "\n",
    "Assuming a binary model for data sharing/hiding decisions, we can form an equivalent classification table:\n",
    "\n",
    "| Decision | Correct               | Wrong                   |\n",
    "|----------|-----------------------|-------------------------|\n",
    "| Share    | Correctly shared data | Incorrectly shared data |\n",
    "| Hide     | Correctly hidden data | Incorrectly hidden data |\n",
    "\n",
    "It is unlikely that the costs of underperformance are equivalent for incorrectly shared data as compared to incorrectly hidden data. It is also unlikely that the benefits of correctly sharing data exactly match the benefits of correctly hiding data. This means the optimal performing classifier will display a appropriate bias to account for the different misclassification costs. Signal Detection Theory provides a mathematical tool called Reciever Operating Characteristic Curve (ROC Curve) to measure and analyse (characterise) this kind of bias.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "\n",
    "It's easy to miss an important point here: The bias that is measured/characterised by ROC Cruve analysis is exactly the same thing as the relative assessments of costs and risks made by the data sharing/hiding decision maker, in a binary forced-choice decision situation. By measuring one, we measure the other.\n",
    "\n",
    "If we are able to conduct experiments that allow us to perform ROC Curve analysis on data sharing/hiding decisions in a specific context, then we will be directly measuring the subjective risk and value assessments of the decision maker.\n",
    "\n",
    "This would create two opportunities:\n",
    "* compare subjective and objective risk/value assessment, to evaluate opportunities to improve performance through providing better information and adressing dysfunctional cultural norms\n",
    "* understand the impact on decision performance of \"adjusting sensitivity\", e.g. by recalibrating risk posture\n",
    "\n",
    "More Reading:\n",
    "* example of comparative analysis in OH&S Domain: http://www.tandfonline.com/doi/pdf/10.1080/10803548.2010.11076826\n",
    "* https://en.wikipedia.org/wiki/Risk_aversion_%28psychology%29\n",
    "\n",
    "\n",
    "## The deeper question: To share or not to share\n",
    "\n",
    "Once we have the apparatus to experiment with forced-choice data sharing decisions, we will have the ability to model and measure the domain, identify and correct cultural bias, and adopt the most appropriate risk posture for optimal outcomes.\n",
    "\n",
    "The next step is to terraform that landscape for even better outcomes, by leveraging behavioral insights and other dark magic. For example, see this \"lapse of non-evil\" post on the robotics stackexchange:\n",
    "\n",
    "http://robotics.stackexchange.com/questions/1266/what-reward-function-results-in-optimal-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
